{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: quick review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll denote the label as $Y$, and the set of observed features as a feature vector \n",
    "$x = [x_1, x_2,\\ldots x_d]$.\n",
    "\n",
    "We define $Y=1$ if an individual earned > 50,000 dollars and $Y=0$ otherwise.\n",
    "\n",
    "In Logistic Regression, the probability of the label being positive ($Y=1$) given the features \n",
    "$x$ is given as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(Y = 1 | X) = \\frac{1}{ 1 + \\exp(- (w^\\top x + b))}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "- $w = [w_1, w_2, \\ldots, w_d]$ are the model weights.\n",
    "- $b$ is the bias of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Model**\n",
    "\n",
    "- we can see that:\n",
    "$w^\\top x + b = b + w_1 x_1 + \\ldots + w_d x_d$\n",
    "is a linear model where the output is a linear function of the input features \n",
    "$x$. \n",
    "\n",
    "- The bias $b$ is the prediction one would make without observing any features. \n",
    "\n",
    "- The model weight $w_i$ reflects how the feature $x_i$ is correlated with the positive label. \n",
    "\n",
    "- If $x_i$ is positively correlated with the positive label, the weight $w_i$ increases, and the probability $P(Y=1|x)$ will be closer to 1. \n",
    "\n",
    "- If $x_i$ is negatively correlated with the positive label, then the weight $w_i$ decreases and the probability $P(Y = 1 | x)$ will be closer to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Function**  (aka the *sigmoid* function) \n",
    "\n",
    "\\begin{equation}\n",
    "S(t) = \\frac{1}{1 + \\exp(-t))}\n",
    "\\end{equation}\n",
    "\n",
    "- applied to the linear model. \n",
    "\n",
    "- converts the output of the linear model $w^\\top x + b$ from any real number into the range of $[0, 1]$, which can be interpreted as a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's plot the logistic function.\n",
    "import math\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xx = np.linspace(-8, 8, 100)\n",
    "yy = np.divide(1, 1 + np.exp(-xx))\n",
    "plt.plot(xx, yy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model training*** is an optimization problem:\n",
    "\n",
    "The goal is to find a set of model weights (i.e. model parameters) to minimize a loss function (typically the cross entropy) defined over the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the sparse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we'll be using is the [Census Income Dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import urllib\n",
    "train_file = tempfile.NamedTemporaryFile()\n",
    "test_file = tempfile.NamedTemporaryFile()\n",
    "urllib.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", train_file.name)\n",
    "urllib.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", test_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the CSV files are downloaded, let's read them into [Pandas](http://pandas.pydata.org/) dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "COLUMNS = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "           \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "           \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "           \"income_bracket\"]\n",
    "df_train = pd.read_csv(train_file, names=COLUMNS, skipinitialspace=True)\n",
    "df_test = pd.read_csv(test_file, names=COLUMNS, skipinitialspace=True, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have:\n",
    "- 32561 training data samples\n",
    "- 16281 test data samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary classification** problem, where the label is:\n",
    "* 1 if the income is over 50K\n",
    "* 0 otherwise\n",
    "\n",
    "We will construct a label column named \"label\" whose value is 1 if the income is over 50K, and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL_COLUMN = \"label\"\n",
    "df_train[LABEL_COLUMN] = (df_train[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)\n",
    "df_test[LABEL_COLUMN] = (df_test[\"income_bracket\"].apply(lambda x: \">50K\" in x)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns can be grouped into two types **categorical** and **continuous** columns:\n",
    "\n",
    "* A column is called **categorical** if its value can only be one of the categories in a finite set (e.g., country)\n",
    "* A column is called **continuous** if its value can be any numerical value in a continuous range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital_status\", \"occupation\",\n",
    "                       \"relationship\", \"race\", \"gender\", \"native_country\"]\n",
    "CONTINUOUS_COLUMNS = [\"age\", \"education_num\", \"capital_gain\", \"capital_loss\", \"hours_per_week\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a list of columns we will use from the Census Income dataset:\n",
    "\n",
    "\n",
    "| Column Name   | Type          | Description      |\n",
    "| ------------- |:-------------:| ---------------|\n",
    "| age\t| Continuous |\tThe age of the individual |\n",
    "| workclass\t| Categorical\t| The type of employer the individual has |\n",
    "| education | Categorical | The highest level of education achieved for that individual |\n",
    "| education_num | Continuous | The highest level of education in numerical form |\n",
    "| marital_status | Categorical | Marital status of the individual |\n",
    "| occupation | Categorical | The occupation of the individual |\n",
    "| relationship | Categorical | Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried |\n",
    "| race | Categorical | White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black |\n",
    "| gender | Categorical | Female, Male |\n",
    "| capital_gain | Continuous | Capital gains recorded |\n",
    "| capital_loss | Continuous | Capital Losses recorded |\n",
    "| hours_per_week | Continuous | Hours worked per week |\n",
    "| native_country | Categorical | Country of origin of the individual |\n",
    "| income | Categorical |\t\">50K\" or \"<=50K\" |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Data into Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data is specified by means of an Input Builder function.  This builder function will not be called until it is later passed to TF.Learn methods such as *fit* and *evaluate*.\n",
    "\n",
    "This Input Builder function returns the following as a pair:\n",
    "* **feature_cols**: A dict from feature column names to [Tensors](https://www.tensorflow.org/versions/r0.9/api_docs/python/framework.html#Tensor) or [SparseTensors](https://www.tensorflow.org/versions/r0.9/api_docs/python/sparse_ops.html#SparseTensor).\n",
    "* **label**: A Tensor containing the label column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each continuous column in the train or test dataframe will be converted into a Tensor, which in general is a good format to represent dense data. \n",
    "* For categorical data, we must represent the data as a SparseTensor. This data format is good for representing sparse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def input_fn(df):\n",
    "  # Creates a dictionary mapping from each continuous feature column name (k) to\n",
    "  # the values of that column stored in a constant Tensor.\n",
    "  continuous_cols = {k: tf.constant(df[k].values)\n",
    "                     for k in CONTINUOUS_COLUMNS}\n",
    "  # Creates a dictionary mapping from each categorical feature column name (k)\n",
    "  # to the values of that column stored in a tf.SparseTensor.\n",
    "  categorical_cols = {k: tf.SparseTensor(\n",
    "      indices=[[i, 0] for i in range(df[k].size)],\n",
    "      values=df[k].values,\n",
    "      shape=[df[k].size, 1])\n",
    "                      for k in CATEGORICAL_COLUMNS}\n",
    "  # Merges the two dictionaries into one.\n",
    "  feature_cols = dict(continuous_cols.items() + categorical_cols.items())\n",
    "  # Converts the label column into a constant Tensor.\n",
    "  label = tf.constant(df[LABEL_COLUMN].values)\n",
    "  # Returns the feature columns and the label.\n",
    "  return feature_cols, label\n",
    "\n",
    "def train_input_fn():\n",
    "  return input_fn(df_train)\n",
    "\n",
    "def eval_input_fn():\n",
    "  return input_fn(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Selecting the right set of feature columns is key to learning an effective model!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We distinguish between\n",
    "\n",
    "* **Base** feature columns: a raw column in the original dataframe\n",
    "\n",
    "* **Derived** feature columns: any new columns created based on some transformations defined over one or multiple base columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Categorical Feature Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define a feature column for a categorical feature, we can create a **SparseColumn** using the TF.Learn API.\n",
    "\n",
    "* If you know the set of all possible feature values of a column and there are only a few of them, you can use **sparse_column_with_keys**. \n",
    "* Each key in the list will get assigned an auto-incremental ID starting from 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gender = tf.contrib.layers.sparse_column_with_keys(column_name=\"gender\",\n",
    "                                                   keys=[\"female\", \"male\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we don't know the set of possible values in advance? \n",
    "\n",
    "We can use **sparse_column_with_hash_bucket** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "education = tf.contrib.layers.sparse_column_with_hash_bucket(\"education\",\n",
    "                                                             hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each possible value in the feature column education will be hashed to an integer ID as we encounter them in training. For example:\n",
    "\n",
    "\n",
    "| ID     | Feature    |\n",
    "| ------ |------------|\n",
    "| ...    | ...  |\n",
    "| 9      | \"Bachelors\" |\n",
    "| ...    | ...  |\n",
    "| 103    | \"Doctorate\" |\n",
    "| ...    | ...  |\n",
    "| 375    | \"Masters\" |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each feature string will be mapped into an integer ID by looking up a fixed mapping or by hashing\n",
    "* Hashing collisions are possible (but may not significantly impact the model quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Under the hood, the LinearModel class is responsible for managing the mapping and creating **tf.Variable** to store the model parameters (also known as model weights) for each feature ID. \n",
    "* The model parameters will be learned through the model training process we'll go through later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the similar trick to define the other categorical features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "race = tf.contrib.layers.sparse_column_with_keys(column_name=\"race\", keys=[\n",
    "  \"Amer-Indian-Eskimo\", \"Asian-Pac-Islander\", \"Black\", \"Other\", \"White\"])\n",
    "marital_status = tf.contrib.layers.sparse_column_with_hash_bucket(\"marital_status\", hash_bucket_size=100)\n",
    "relationship = tf.contrib.layers.sparse_column_with_hash_bucket(\"relationship\", hash_bucket_size=100)\n",
    "workclass = tf.contrib.layers.sparse_column_with_hash_bucket(\"workclass\", hash_bucket_size=100)\n",
    "occupation = tf.contrib.layers.sparse_column_with_hash_bucket(\"occupation\", hash_bucket_size=1000)\n",
    "native_country = tf.contrib.layers.sparse_column_with_hash_bucket(\"native_country\", hash_bucket_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Continuous Feature Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can define a **RealValuedColumn** for each continuous feature column that we want to use in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = tf.contrib.layers.real_valued_column(\"age\")\n",
    "education_num = tf.contrib.layers.real_valued_column(\"education_num\")\n",
    "capital_gain = tf.contrib.layers.real_valued_column(\"capital_gain\")\n",
    "capital_loss = tf.contrib.layers.real_valued_column(\"capital_loss\")\n",
    "hours_per_week = tf.contrib.layers.real_valued_column(\"hours_per_week\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Continuous Features Categorical through Bucketization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the relationship between a continuous feature and the label is not linear. \n",
    "\n",
    "As an hypothetical example, a person's income may grow with age in the early stage of one's career, then the growth may slow at some point, and finally the income decreases after retirement. In this scenario, using the raw age as a real-valued feature column might not be a good choice because the (linear) model can only learn one of the three cases:\n",
    "\n",
    "1. Income always increases at some rate as age grows (positive correlation),\n",
    "2. Income always decreases at some rate as age grows (negative correlation), or\n",
    "3. Income stays the same no matter at what age (no correlation)\n",
    "\n",
    "If we want to learn the fine-grained correlation between income and each age group seperately, we can leverage **bucketization**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### Bucketization is a process of dividing the entire range of a continuous feature into a set of consecutive bins/buckets, and then converting the original numerical feature into a bucket ID (as a categorical feature) depending on which bucket that value falls into\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can define a **bucketized_column** over age as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_buckets = tf.contrib.layers.bucketized_column(age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are 10 boundaries, resulting in 11 age group buckets (from age 17 and below, 18-24, 25-29, ..., to 65 and over)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersecting Multiple Columns with CrossedColumn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using each feature column separately may not be enough to explain the data \n",
    "\n",
    "- For example, the correlation between education and the label (earning > 50,000 dollars) may be different for different occupations (e.g. we want to distinguish between *education=\"Bachelors\"* AND *occupation=\"Exec-managerial\"* and *education=\"Bachelors\" AND occupation=\"Craft-repair\"*)\n",
    "\n",
    "- To learn the differences between different feature combinations, we can add crossed feature columns to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "education_x_occupation = tf.contrib.layers.crossed_column([education, occupation], hash_bucket_size=int(1e4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a **CrossedColumn** over more than two columns. Each constituent column can be either a base feature column that is categorical (SparseColumn), a bucketized real-valued feature column (BucketizedColumn), or even another CrossColumn.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_buckets_x_race_x_occupation = tf.contrib.layers.crossed_column(\n",
    "  [age_buckets, race, occupation], hash_bucket_size=int(1e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section we've seen several types of base and derived feature columns, including:\n",
    "\n",
    "* SparseColumn\n",
    "* RealValuedColumn\n",
    "* BucketizedColumn\n",
    "* CrossedColumn\n",
    "\n",
    "All of these are subclasses of the abstract **FeatureColumn** class, and can be added to the feature_columns field of a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "m = tf.contrib.learn.LinearClassifier(feature_columns=[\n",
    "  gender, native_country, education, occupation, workclass, marital_status, race,\n",
    "  age_buckets, education_x_occupation, age_buckets_x_race_x_occupation],\n",
    "  model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model also automatically learns a bias term\n",
    "\n",
    "The learned model files will be stored in *model_dir*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a model is just a one-liner using the TF.Learn API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.fit(input_fn=train_input_fn, steps=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is trained, we can evaluate how good our model is at predicting the labels of the holdout data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = m.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results):\n",
    "    print \"%s: %s\" % (key, results[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise1 : Add more features and transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add some extra features (e.g., new crosses to try or new bucketized features.)\n",
    "extra_features = tf.contrib.layers.crossed_column([], hash_bucket_size=int(1e4))\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "\n",
    "m_more = tf.contrib.learn.LinearClassifier(feature_columns=[\n",
    "  gender, native_country, education, occupation, workclass, marital_status, race,\n",
    "  age_buckets, education_x_occupation, age_buckets_x_race_x_occupation, extra_features],\n",
    "  model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_more.fit(input_fn=train_input_fn, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_more = m_more.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results_more):\n",
    "    print \"%s: %s\" % (key, results_more[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Regularization against over-fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regularization is a technique used to avoid *overfitting*. \n",
    "\n",
    "- Overfitting happens when your model does well on the data it is trained on, but worse on test data that the model has not seen before, such as live traffic. \n",
    "\n",
    "- Overfitting generally occurs when a model is excessively complex, such as having too many parameters relative to the number of observed training data. \n",
    "\n",
    "- Regularization allows for you to control your model's complexity and makes the model more generalizable to unseen data.\n",
    "\n",
    "In the Linear Model library, you can add L1 and L2 regularizations to the model as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = tempfile.mkdtemp()\n",
    "\n",
    "m_reg = tf.contrib.learn.LinearClassifier(feature_columns=[\n",
    "  gender, native_country, education, occupation, workclass, marital_status, race,\n",
    "  age_buckets, education_x_occupation, age_buckets_x_race_x_occupation],\n",
    "  optimizer=tf.train.FtrlOptimizer(\n",
    "    learning_rate=0.1,\n",
    "    l1_regularization_strength=1.0,\n",
    "    l2_regularization_strength=1.0),\n",
    "  model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L1 regularization tends to make model weights stay at zero (creating sparser models)\n",
    "\n",
    "- L2 regularization also tries to make the model weights closer to zero but not necessarily zero. \n",
    "\n",
    "Therefore, if you increase the strength of L1 regularization, you will have a smaller model size because many of the model weights will be zero. This is often desirable when the feature space is very large but sparse, and when there are resource constraints that prevent you from serving a model that is too large.\n",
    "\n",
    "In practice, you should try various combinations of L1, L2 regularization strengths and find the best parameters that best control overfitting and give you a desirable model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_reg.fit(input_fn=train_input_fn, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = m_reg.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results):\n",
    "    print \"%s: %s\" % (key, results[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 1: Possible solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "education_x_country = tf.contrib.layers.crossed_column([education, native_country], hash_bucket_size=int(1e4))\n",
    "\n",
    "capital_gain_buckets = tf.contrib.layers.bucketized_column(\n",
    "    capital_gain, boundaries=[5000, 20000, 30000, 50000, 70000, 100000])\n",
    "\n",
    "model_dir = tempfile.mkdtemp()\n",
    "\n",
    "m_more = tf.contrib.learn.LinearClassifier(feature_columns=[\n",
    "  gender, native_country, education, occupation, workclass, marital_status, race,\n",
    "  age_buckets, education_x_occupation, education_x_country, age_buckets_x_race_x_occupation,\n",
    "    capital_gain_buckets],\n",
    "  model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m_more.fit(input_fn=train_input_fn, steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_more = m_more.evaluate(input_fn=eval_input_fn, steps=1)\n",
    "for key in sorted(results_more):\n",
    "    print \"%s: %s\" % (key, results_more[key])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
