{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images of handwritten digits: ![Alt][1]\n",
    "[1]: https://www.tensorflow.org/versions/r0.10/images/MNIST.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For each image we have a label telling us which digit it is\n",
    "* The MNIST data is hosted on [Yann LeCun's website](http://yann.lecun.com/exdb/mnist/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data is split into three parts: \n",
    "* **mnist.train** : 55,000 data points of training set \n",
    "* **mnist.test** : 10,000 data points of test set \n",
    "* **mnist.validation** : 5,000 data points of validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every MNIST data point has two parts: \n",
    "* an image of a handwritten digit (called \"x\")\n",
    "* a corresponding label (called \"y\").\n",
    "\n",
    "Both the training set and test set contain images and their corresponding labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is 28 pixels by 28 pixels (array of numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt][1]\n",
    "[1]:  https://www.tensorflow.org/versions/r0.10/images/MNIST-Matrix.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The array can be flattened into a vector of 28x28 = 784 numbers\n",
    "* Flattening ignores the 2D spatial structure of the images\n",
    "* The dataset becomes a point cloud into the 784-dimensional space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the images tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* mnist.train.images is a tensor (an n-dimensional array) with a shape of [55000, 784]\n",
    "* The first dimension is an index into the list of images \n",
    "* The second dimension is the index for each pixel in each image\n",
    "* Each entry in the tensor is a pixel intensity between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt][1]\n",
    "[1]: https://www.tensorflow.org/versions/r0.10/images/mnist-train-xs.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the labels tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label is a number between 0 and 9 representing the digit drawn in the image.\n",
    "\n",
    "* The labels are represented as \"*one-hot vectors*\". A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the n-th digit will be represented as a vector which is 1 in the n-th dimensions. For example, 3 would be\n",
    "\\[\n",
    "0\n",
    "0\n",
    "0\n",
    "1\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\n",
    "0\\]\n",
    ". \n",
    "\n",
    "* The mnist.train.labels is a [55000, 10] array of floats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt][1]\n",
    "[1]: https://www.tensorflow.org/versions/r0.10/images/mnist-train-ys.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression: theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are only 10 possible classes \n",
    "* We want to estimate the probabilities for the image being each digit class\n",
    "\n",
    "Softmax regression fits naturally here\n",
    "* Collect evidence that an data sample falls into a class\n",
    "* Convert this evidence into a probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence that a given image is in a particular class: weighted sum of the pixel intensities. \n",
    "\n",
    "The weight is:\n",
    "- negative if that pixel having a high intensity is evidence against the image being in that class, \n",
    "- positive if it is evidence in favor.\n",
    "\n",
    "We also add some extra evidence called a *bias* (to be able to say that some things are more likely independent of the input).\n",
    "\n",
    "The **evidence** for a class i given an input x is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\rm evidence} = \\sum_j W_{ij} x_j + b_i\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where:\n",
    "- $W_i$ and $b_i$ is the weight and bias resp. for the i-th digit class.\n",
    "\n",
    "- $j$ is an index for summing over the pixels in our input image $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert the evidence sums into our predicted probabilities $y$ using the **softmax** function:\n",
    "\n",
    "\\begin{equation}\n",
    "y = {\\rm softmax} ({\\rm evidence})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "{\\rm softmax}(x)_i = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n",
    "\\end{equation}\n",
    "\n",
    "It results a valid probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each output, we compute a weighted sum of the $x$s, add a bias, and then apply softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt][1]\n",
    "\n",
    "[1]: https://www.tensorflow.org/versions/r0.10/images/softmax-regression-scalargraph.png\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In form of equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt][1]\n",
    "\n",
    "[1]: https://www.tensorflow.org/versions/r0.10/images/softmax-regression-scalarequation.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt][1]\n",
    "[1]: https://www.tensorflow.org/versions/r0.10/images/softmax-regression-vectorequation.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In compact form:\n",
    "\n",
    "\\begin{equation}\n",
    "y = {\\rm softmax}(W x + b)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression: implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a symbolic variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $x$ is a placeholder, a value that we'll input when we ask TensorFlow to run a computation \n",
    "* We want to be able to input *any number of* MNIST images, each flattened into a 784-dimensional vector\n",
    "* The input tensor $x$ is represented as a 2-D tensor of floating-point numbers, with a shape [None, 784]. \n",
    "* *None* means that a dimension can be of any length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the weights and biases for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variables are modifiable tensors\n",
    "* **Model parameters in ML are typically defined as variables**\n",
    "* Here they are initialized to zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that:\n",
    "- W has a shape of [784, 10] because we want to multiply the 784-dimensional image vectors by it to produce 10-dimensional vectors of evidence for the difference classes. \n",
    "- b has a shape of [10] so we can add it to the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to define our model. It only takes one line to define it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss**: represents how far off our model is from our desired outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function we will use: **cross-entropy**\n",
    "\n",
    "The cross-entropy is measuring how inefficient our predictions are for describing the true labels.\n",
    "\n",
    "\\begin{equation}\n",
    "H(y) =  - \\sum_i y^\\prime_i \\log(y_i)\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "* $y$: predicted labels\n",
    "* $y^\\prime$: true labels\n",
    "\n",
    "More information about cross-entropy can be found [here](http://colah.github.io/posts/2015-09-Visual-Information/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a placeholder to input the correct answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf.log(y) computes the logarithm of each element of y. \n",
    "* Next, each element of y_ is multiplied with the corresponding element of tf.log(y). \n",
    "* Then tf.reduce_sum adds the elements in the second dimension of y, due to the reduction_indices=[1] parameter. \n",
    "* Finally, tf.reduce_mean computes the mean over all the examples in the batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to set the optimizer\n",
    "\n",
    "- TensorFlow knows the whole graph of computations\n",
    "- It can use the [Backpropagation algorithm](http://colah.github.io/posts/2015-08-Backprop/) to compute how the loss is affected by each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We ask TensorFlow to minimize cross_entropy using the gradient descent algorithm with a learning rate of 0.5.\n",
    "* Gradient descent simply shifts each variable a little bit in the direction that reduces the loss\n",
    "* Many other [optimizers](https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html#optimizers) are available in TensorFlow\n",
    "* TensorFlow (behind the scenes) adds new operations to the graph which implement backpropagation and gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training step 1000 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each step of the loop, we get a \"batch\" of one hundred random data points from our training set\n",
    "* Using small batches of random data is called *stochastic training*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tf.argmax() gives you the index of the highest entry in a tensor along some axis\n",
    "* tf.equal() gives us a list of booleans. \n",
    "* To determine what fraction are correct, we cast to floating point numbers and then take the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to compute the accuracy on our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 : Convergence plots (training & eval loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect the training and eval loss values during training.\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 : Visualize the weight matrices for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "# Put your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot training and eval loss values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect the training and eval loss values during training.\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "loss_array = []\n",
    "eval_loss_array = []\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  _, current_loss = sess.run([train_step, cross_entropy], feed_dict={x: batch_xs, y_: batch_ys})\n",
    "  loss_array.append(current_loss)\n",
    "  current_eval_loss = sess.run([cross_entropy], feed_dict={x: mnist.test.images, y_: mnist.test.labels})\n",
    "  eval_loss_array.append(current_eval_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot training and eval loss values.\n",
    "f, axarr = plt.subplots(1, 2,  figsize=(10, 5))\n",
    "axarr[0].plot(loss_array)\n",
    "axarr[0].set_title('Training loss')\n",
    "\n",
    "axarr[1].plot(eval_loss_array)\n",
    "axarr[1].set_title('Eval loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "\n",
    "W_array = sess.run(W)\n",
    "print W_array.shape\n",
    "\n",
    "img = W_array[:, 0].reshape(28, 28)\n",
    "imgplot = plt.imshow(img)\n",
    "plt.colorbar()\n",
    "\n",
    "f, axarr = plt.subplots(2, 5, figsize=(15, 7))\n",
    "for i in range(0, 2):\n",
    "    for j in range(0, 5):\n",
    "        digit_class = i * 5 + j\n",
    "        axarr[i, j].imshow(W_array[:, digit_class].reshape(28,28))\n",
    "        axarr[i, j].set_title(str(digit_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
