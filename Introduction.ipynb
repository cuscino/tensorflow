{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rb5rSpcZvYbX"
   },
   "source": [
    "# Overview\n",
    "\n",
    "TensorFlow is a general-purpose system for graph-based computation. A typical use is machine learning. In this notebook, we'll introduce the basic concepts of TensorFlow using some simple examples.\n",
    "\n",
    "TensorFlow gets its name from [tensors](https://en.wikipedia.org/wiki/Tensor), which are arrays of arbitrary dimensionality. A vector is a 1-d array and is known as a 1st-order tensor. A matrix is a 2-d array and a 2nd-order tensor. The \"flow\" part of the name refers to computation flowing through a graph. Training and inference in a neural network, for example, involves the propagation of matrix computations through many nodes in a computational graph.\n",
    "\n",
    "When you think of doing things in TensorFlow, you might want to think of creating tensors (like matrices), adding operations (that output other tensors), and then executing the computation (running the computational graph). In particular, it's important to realize that when you add an operation on tensors, it doesn't execute immediately. Rather, TensorFlow waits for you to define all the operations you want to perform. Then, TensorFlow optimizes the computation graph, deciding how to execute the computation, before generating the data. Because of this, a tensor in TensorFlow isn't so much holding the data as a placeholder for holding the data, waiting for the data to arrive when a computation is executed.\n",
    "\n",
    "A TensorFlow graph is a description of computations. To compute anything, a graph must be launched in a Session. A Session places the graph ops onto Devices, such as CPUs or GPUs, and provides methods to execute them. These methods return tensors produced by ops as [numpy](www.numpy.org) ndarray objects in Python, and as tensorflow::Tensor instances in C and C++.\n",
    "\n",
    "To use TensorFlow you need to understand how TensorFlow:\n",
    "\n",
    "- Represents computations as graphs.\n",
    "- Executes graphs in the context of Sessions.\n",
    "- Represents data as tensors.\n",
    "- Maintains state with Variables.\n",
    "- Uses feeds and fetches to get data into and out of arbitrary operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The computation graph\n",
    "\n",
    "TensorFlow programs are usually structured into a construction phase, that assembles a graph, and an execution phase that uses a session to execute ops in the graph.\n",
    "\n",
    "For example, it is common to create a graph to represent and train a neural network in the construction phase, and then repeatedly execute a set of training ops in the graph in the execution phase.\n",
    "\n",
    "TensorFlow can be used from C, C++, and Python programs. It is presently much easier to use the Python library to assemble graphs, as it provides a large set of helper functions not available in the C and C++ libraries.\n",
    "\n",
    "The session libraries have equivalent functionalities for the three languages.\n",
    "\n",
    "## Building the graph\n",
    "\n",
    "To build a graph start with ops that do not need any input (source ops), such as Constant, and pass their output to other ops that do computation.\n",
    "\n",
    "The ops constructors in the Python library return objects that stand for the output of the constructed ops. You can pass these to other ops constructors to use as inputs.\n",
    "\n",
    "The TensorFlow Python library has a default graph to which ops constructors add nodes. The default graph is sufficient for many applications. See the [Graph class](https://www.tensorflow.org/versions/r0.10/api_docs/python/framework.html#Graph) documentation for how to explicitly manage multiple graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "#\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix\n",
    "# multiplication.\n",
    "product = tf.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default graph now has three nodes: two constant() ops and one matmul() op. To actually multiply the matrices, and get the result of the multiplication, you must launch the graph in a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the operations included in the default graph. Additional operations will be added to the same graph until we\n",
    "# restart the kernel. \n",
    "print tf.Graph.as_graph_def(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launching the graph in a session\n",
    "\n",
    "Launching follows construction. To launch a graph, create a Session object. Without arguments the session constructor launches the default graph.\n",
    "\n",
    "See the [Session class](https://www.tensorflow.org/versions/r0.10/api_docs/python/client.html#session-management) for the complete session API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Launch the default graph.\n",
    "sess = tf.Session()\n",
    "\n",
    "# To run the matmul op we call the session 'run()' method, passing 'product'\n",
    "# which represents the output of the matmul op.  This indicates to the call\n",
    "# that we want to get the output of the matmul op back.\n",
    "#\n",
    "# All inputs needed by the op are run automatically by the session.  They\n",
    "# typically are run in parallel.\n",
    "#\n",
    "# The call 'run(product)' thus causes the execution of three ops in the\n",
    "# graph: the two constants and matmul.\n",
    "#\n",
    "# The output of the op is returned in 'result' as a numpy `ndarray` object.\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "\n",
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sessions should be closed to release resources. You can also enter a Session with a \"with\" block. The Session closes automatically at the end of the with block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "  result = sess.run(product)\n",
    "  print \"run: \", result\n",
    "    \n",
    "# Equivalent version (in the case of one output tensor)\n",
    "with tf.Session():\n",
    "  result = product.eval()\n",
    "  print \"eval: \", result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TensorFlow implementation translates the graph definition into executable operations distributed across available compute resources, such as the CPU or one of your computer's GPU cards. In general you do not have to specify CPUs or GPUs explicitly. TensorFlow uses your first GPU, if you have one, for as many operations as possible.\n",
    "\n",
    "If you have more than one GPU available on your machine, to use a GPU beyond the first you must assign ops to it explicitly. Use with...Device statements to specify which CPU or GPU to use for operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session():\n",
    "  with tf.device(\"/cpu:0\"):    \n",
    "    matrix1 = tf.constant([[3., 3.]])\n",
    "    matrix2 = tf.constant([[2.],[2.]])\n",
    "    product = tf.matmul(matrix1, matrix2)\n",
    "    print product.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devices are specified with strings. The currently supported devices are:\n",
    "\n",
    "* \"/cpu:0\": The CPU of your machine.\n",
    "* \"/gpu:0\": The GPU of your machine, if you have one.\n",
    "* \"/gpu:1\": The second GPU of your machine, etc.\n",
    "\n",
    "See [Using GPUs](https://www.tensorflow.org/versions/r0.10/how_tos/using_gpu/index.html) for more information about GPUs and TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetches\n",
    "\n",
    "To fetch the outputs of operations, execute the graph with a run() call on the Session object and pass in the tensors to retrieve. In the previous example we fetched the single node state, but you can also fetch multiple tensors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "input1 = tf.constant([3.0])\n",
    "input2 = tf.constant([2.0])\n",
    "input3 = tf.constant([5.0])\n",
    "intermed = tf.add(input2, input3)\n",
    "mul = tf.mul(input1, intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  result = sess.run([mul, intermed])\n",
    "  print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeds\n",
    "\n",
    "The examples above introduce tensors into the computation graph by storing them in Constants. TensorFlow also provides a feed mechanism for patching a tensor directly into any operation in the graph.\n",
    "\n",
    "A feed temporarily replaces the output of an operation with a tensor value. You supply feed data as an argument to a run() call. The feed is only used for the run call to which it is passed. The most common use case involves designating specific operations to be \"feed\" operations by using tf.placeholder() to create them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A placerholder behaves is a tensor that needs to be specified when we run the graph. It generates an error if it\n",
    "# is evaluated and it's not in the feeds.\n",
    "a = tf.constant([3.0])\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = a + b  # This is the same as tf.add(a, b)\n",
    "d = tf.abs(a)\n",
    "e = tf.mul(c, d)  # Entry multiplication.\n",
    "f = tf.square(c)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  print(sess.run([f], feed_dict={b:[7.]}))\n",
    "\n",
    "# But we can feed to any node in the graph, e.g.:\n",
    "with tf.Session() as sess:\n",
    "  print(sess.run([e], feed_dict={c:[8.], d:[3.0]}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the ops needed to produce the values of the requested tensors are run once (not once per requested tensor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "\n",
    "TensorFlow programs use a tensor data structure to represent all data -- only tensors are passed between operations in the computation graph. You can think of a TensorFlow tensor as an n-dimensional array or list. A tensor has a static type, a rank, and a shape.\n",
    "\n",
    "### Rank\n",
    "\n",
    "In the TensorFlow system, tensors are described by a unit of dimensionality known as rank. Tensor rank is not the same as matrix rank. Tensor rank (sometimes referred to as order or degree or n-dimension) is the number of dimensions of the tensor. For example, the following tensor (defined as a Python list) has a rank of 2:\n",
    "\n",
    "t = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "A rank two tensor is what we typically think of as a matrix, a rank one tensor is a vector. For a rank two tensor you can access any element with the syntax t[i, j]. For a rank three tensor you would need to address an element with t[i, j, k].\n",
    "\n",
    "\n",
    "| Rank\t| Math entity\t| Python example |\n",
    "| ------------- |:-------------:| ---------------|\n",
    "|1\t| Vector (magnitude and direction)\t| v = [1.1, 2.2, 3.3] |\n",
    "|2\t| Matrix (table of numbers)\t| m = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] |\n",
    "|3\t| 3-Tensor (cube of numbers) |\tt = [[[2], [4], [6]], [[8], [10], [12]], [[14], [16], [18]]] |\n",
    "|n\t| n-Tensor (you get the idea) |\t.... |\n",
    "\n",
    "### Shape\n",
    "\n",
    "The TensorFlow documentation uses three notational conventions to describe tensor dimensionality: rank, shape, and dimension number. The following table shows how these relate to one another:\n",
    "\n",
    "\n",
    "| Rank\t| Shape\t| Dimension number\t| Example |\n",
    "| ------------- |:-------------:| |:-------------:| ---------------|\n",
    "|0\t| []\t| 0-D\t| A 0-D tensor. A scalar. |\n",
    "|1\t| [D0]\t| 1-D\t| A 1-D tensor with shape [5]. |\n",
    "|2\t| [D0, D1]\t| 2-D\t| A 2-D tensor with shape [3, 4]. |\n",
    "|3\t| [D0, D1, D2]\t| 3-D\t| A 3-D tensor with shape [1, 4, 3]. |\n",
    "|n\t| [D0, D1, ... Dn-1]\t| n-D \t| A tensor with shape [D0, D1, ... Dn-1]. |\n",
    "\n",
    "### Data types\n",
    "\n",
    "In addition to dimensionality, Tensors have a data type. You can assign any one of the following data types to a tensor:\n",
    "\n",
    "| Data type\t| Python type\t| Description |\n",
    "| ------------- |:-------------:| ---------------|\n",
    "|DT_FLOAT\t|tf.float32\t|32 bits floating point.|\n",
    "|DT_DOUBLE\t|tf.float64\t|64 bits floating point.|\n",
    "|DT_INT8\t|tf.int8\t|8 bits signed integer.|\n",
    "|DT_INT16\t|tf.int16\t|16 bits signed integer.|\n",
    "|DT_INT32\t|tf.int32\t|32 bits signed integer.|\n",
    "|DT_INT64\t|tf.int64\t|64 bits signed integer.|\n",
    "|DT_UINT8\t|tf.uint8\t|8 bits unsigned integer.|\n",
    "|DT_STRING\t|tf.string\t|Variable length byte arrays. Each element of a Tensor is a byte array.|\n",
    "|DT_BOOL\t|tf.bool\t|Boolean.|\n",
    "|DT_COMPLEX64\t|tf.complex64\t|Complex number made of two 32 bits floating points: real and imaginary parts.|\n",
    "|DT_COMPLEX128\t|tf.complex128\t|Complex number made of two 64 bits floating points: real and imaginary parts.|\n",
    "|DT_QINT8\t|tf.qint8\t|8 bits signed integer used in quantized Ops.|\n",
    "|DT_QINT32\t|tf.qint32\t|32 bits signed integer used in quantized Ops.|\n",
    "|DT_QUINT8\t|tf.quint8\t|8 bits unsigned integer used in quantized Ops.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Transformations\n",
    "\n",
    "In the documentation a full list of [transformations](https://www.tensorflow.org/versions/r0.10/api_docs/python/array_ops.html#tensor-transformations) is available. Some useful operations are given here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session():   \n",
    "    a = tf.constant(range(0, 12))\n",
    "    print \"a = \", a.eval()\n",
    "    \n",
    "    # tf.reshape(x, shape) reshapes x to a new shape\n",
    "    b = tf.reshape(a, [4, 3])\n",
    "    print \"b = \", b.eval()\n",
    "    c = tf.reshape(a, [2, 2, 3])\n",
    "    print \"c = \", c.eval()\n",
    "    \n",
    "    # tf.size(x) is the size of x, tf.shape(x) the shape\n",
    "    size_c = tf.size(c)\n",
    "    shape_c = tf.shape(c)\n",
    "    print \"size c = \", size_c.eval()\n",
    "    print \"shape c = \", shape_c.eval()\n",
    "    \n",
    "    # tf.slice(x, begin, size). E.g. take last 2 columns of b:\n",
    "    d = tf.slice(b, [0, 1], [4, 2])\n",
    "    print \"d = \", d.eval()\n",
    "    \n",
    "    # tf.reduce_sum(x, reduce_indices)\n",
    "    e = tf.reduce_sum(b, 0)  # sums the rows of b\n",
    "    print \"e = \", e.eval()\n",
    "    f = tf.reduce_sum(b, 1)  # sum the cols of b\n",
    "    print \"f = \", f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "\n",
    "Let's use what we learn so far to complete the following example. We pretend that the input features and labels are defined as constants (we will see later how to load them from file) and we try to solve a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# input_features contains the 4 feature values for 3 samples. We use the first dimension to index the points and the\n",
    "# second to index the features\n",
    "input_features = tf.constant([[0.5, 0.0, 1, 0.7],\n",
    "                              [0.2, 1.0, 0.8, 0.5],\n",
    "                              [0.3, 1.0, 0.5, 0.4]])\n",
    "# input_groundtruth contains the target values for the 3 points. We use a rank 1 tensor.\n",
    "input_groundtruth = tf.constant([0.0, 1.0, 1.0])\n",
    "\n",
    "# We transform every point x by applying a linear transformation, i.e.:\n",
    "# y = sum w[i] * x[i] + bias\n",
    "# This needs to be done for every x in input_features (rows.) and the result must be stored in a row of the prediction\n",
    "# tensor.\n",
    "w = tf.random_normal([4, 1], stddev=0.35)\n",
    "bias = tf.random_uniform([1], minval=-1, maxval=1)\n",
    "\n",
    "# YOUR CODE HERE.\n",
    "# prediction has shape [3, 1], every row is one of the vector y defined above\n",
    "prediction = tf.matmul(input_features, w) + bias\n",
    "\n",
    "# YOUR CODE HERE.\n",
    "# Assume we want to solve a regression problem. We want to compare the values of prediction with input_groundtruth.\n",
    "# quadratic_error is a rank 1 tensor containing sum (input_groundtruth[i] - prediction[i]) ^ 2\n",
    "quadratic_error = tf.reduce_sum(tf.square(prediction - input_groundtruth))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    [w_eval, bias_eval, prediction_eval, quadratic_error_eval] = sess.run([w, bias, prediction, quadratic_error])\n",
    "    print \"w = \", w_eval\n",
    "    print \"bias = \", bias_eval\n",
    "    print \"prediction = \", prediction_eval\n",
    "    print \"quadratic_error_eval = \", quadratic_error_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Variables maintain state across executions of the graph. When you train a model, you use variables to hold and update parameters. Variables are in-memory buffers containing tensors. They must be explicitly initialized and can be saved to disk during and after training. You can later restore saved values to exercise or analyse the model.\n",
    "\n",
    "See [Variables](https://www.tensorflow.org/versions/r0.10/how_tos/variables/index.html) for details about variables.\n",
    " \n",
    "### Creation\n",
    "\n",
    "When you create a Variable you pass a Tensor as its initial value to the Variable() constructor. TensorFlow provides a collection of ops that produce tensors often used for initialization from constants or random values.\n",
    "\n",
    "Note that all these ops require you to specify the shape of the tensors. That shape automatically becomes the shape of the variable. Variables generally have a fixed shape, but TensorFlow provides advanced mechanisms to reshape variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reset graph.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Same as above.\n",
    "input_features = tf.constant([[0.5, 0.0, 1, 0.7],\n",
    "                              [0.2, 1.0, 0.8, 0.5],\n",
    "                              [0.3, 1.0, 0.5, 0.4]])\n",
    "input_groundtruth = tf.constant([0.0, 1.0, 1.0])\n",
    "\n",
    "# Create two variables.\n",
    "w = tf.Variable(tf.random_normal([4, 1], stddev=0.35),\n",
    "                name=\"weights\")\n",
    "bias = tf.Variable(tf.zeros([1]), name=\"bias\")\n",
    "\n",
    "# Same as above.\n",
    "prediction = tf.matmul(input_features, w) + bias\n",
    "quadratic_error = tf.reduce_sum(tf.square(prediction - input_groundtruth))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    "\n",
    "Variable initializers must be run explicitly before other ops in your model can be run. The easiest way to do that is to add an op that runs all the variable initializers, and run that op before using the model.\n",
    "\n",
    "You can alternatively restore variable values from a checkpoint file.\n",
    "\n",
    "Use tf.initialize_all_variables() to add an op to run variable initializers. Only run that op after you have fully constructed your model and launched it in a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add an op to initialize the variables.\n",
    "init_op = tf.initialize_all_variables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update\n",
    "\n",
    "Variables can be updated using the assign operation, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is a list of update operations.\n",
    "update = [w.assign(w + 0.01), bias.assign(bias - 0.1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Runs the init op. Note that run takes also operations.\n",
    "    sess.run(init_op)\n",
    "    for i in range(3):\n",
    "        [w_eval, bias_eval, prediction_eval, quadratic_error_eval] = sess.run([w, bias, prediction, quadratic_error])\n",
    "        print \"Iteration \", i\n",
    "        print \"w = \", w_eval\n",
    "        print \"bias = \", bias_eval\n",
    "        print \"prediction = \", prediction_eval\n",
    "        print \"quadratic_error_eval = \", quadratic_error_eval\n",
    "        # Runs the op that updates 'w' and 'bias'\n",
    "        sess.run(update)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assign() operation in this code is a part of the expression graph just like the matmul() operation, so it does not actually perform the assignment until run() executes the expression.\n",
    "\n",
    "You typically represent the parameters of a statistical model as a set of Variables. For example, you would store the weights for a neural network as a tensor in a Variable. During training you update this tensor by running a training graph repeatedly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "You can already run the graph for multiple values of the parameters and find those the minimize the quadratic error. However, this is slow and inefficient. Instead, you can use one of the provided optimizers. You will see more about this in the next tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "update = tf.train.GradientDescentOptimizer(0.01).minimize(quadratic_error)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Runs the init op. Note that run takes also operations.\n",
    "    sess.run(init_op)\n",
    "    for i in range(3):\n",
    "        [w_eval, bias_eval, prediction_eval, quadratic_error_eval] = sess.run([w, bias, prediction, quadratic_error])\n",
    "        print \"Iteration \", i\n",
    "        print \"w = \", w_eval\n",
    "        print \"bias = \", bias_eval\n",
    "        print \"prediction = \", prediction_eval\n",
    "        print \"quadratic_error_eval = \", quadratic_error_eval\n",
    "        # Runs the op that updates 'w' and 'bias'\n",
    "        sess.run(update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saver\n",
    "\n",
    "The [Saver](https://www.tensorflow.org/versions/r0.10/api_docs/python/state_ops.html#Saver) adds ops to save and restore variables to and from checkpoints. It also provides convenience methods to run these ops. Note that there is no need to save other tensors, since they can be recomputed from the graph.\n",
    "\n",
    "Checkpoints are binary files in a proprietary format which map variable names to tensor values. The best way to examine the contents of a checkpoint is to load it using a Saver.\n",
    "\n",
    "Savers can automatically number checkpoint filenames with a provided counter. This lets you keep multiple checkpoints at different steps while training a model. For example you can number the checkpoint filenames with the training step number. To avoid filling up disks, savers manage checkpoint files automatically. For example, they can keep only the N most recent files, or one checkpoint for every N hours of training.\n",
    "\n",
    "You number checkpoint filenames by passing a value to the optional global_step argument to save():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()  # Creates the saver\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Runs the init op. Note that run takes also operations.\n",
    "    sess.run(init_op)\n",
    "    for i in range(123):\n",
    "        sess.run(update)\n",
    "    [w_eval, bias_eval] = sess.run([w, bias])\n",
    "    print \"Final parameters\\nw = \", w_eval, \"\\nbias = \", bias_eval\n",
    "    s = saver.save(sess, 'my-model', global_step=123)  # Saves to my-model-123\n",
    "    print \"Saved to \", s\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables can be restored later from one of the checkpoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reset graph.\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# To load the variables I need to recreate them. Normally we recreate the whole graph, but some parts may not be\n",
    "# necessary.\n",
    "w = tf.Variable(tf.random_normal([4, 1], stddev=0.35),\n",
    "                name=\"weights\")\n",
    "bias = tf.Variable(tf.zeros([1]), name=\"bias\")\n",
    "saver = tf.train.Saver() \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\".\"))  # Same as \"my-model-123\".\n",
    "    [w_eval, bias_eval] = sess.run([w, bias])\n",
    "    print \"Restored parameters\\nw = \", w_eval, \"\\nbias = \", bias_eval"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Untitled",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
